\chapter{Methodology}

\section{Porting the Reference Implementation}

With all the equations from the xTB paper now in place, the next step is to implement them in code. Writing another Python re-implementation might seem rendundant, but the purpose of doing so is to start with a sequential version that is hopefully easier to reason about, and which is structured in a way that can more easily be translated to parallel GPU code.

We started implementing the equations from the paper directly, but found that it gave results different from the Fortran implementation. It is not that the Fortran code does it differently from what is described in the paper, but rather that there are details that might appear obvious to a chemist, which is not explicitly described in the paper. In \cite{bannwarth2019} it is not specified in equation $9$ for repulsion energy \eqref{eq:repulsion1}, that A and B cannot be the same atom index. They cannot be the same because $R_{AB}$ is the distance between the two atoms, so if A and B is the same, then the distance is $0$, which will result in division by zero. This makes sense intuitively because an atom does not repulse itself, but this is not always immediatly apparent to someone outside the field.

\begin{align}
  \E{rep} &= \frac{1}{2}\sum_{A,B}\frac{Z^{eff}_A Z^{eff}_B}{R_{AB}}e^{-\sqrt{a_Aa_B}(R_{AB})^{(k_f)}} \label{eq:repulsion1}
\end{align}

%Another example is that they do not explain clearly that the covalent radii of the atoms are different for equation 18 and 19 in the paper. For equation 19, the covalent radii is apparently computed from the dispersion model.


In \cite{grimme2017} they write that they use SCC, but they do not mention which method they use. It turns out that they use Broyden's method. The unit convertions between angstrÃ¶m and bohr that are applied to the input geometry data, does also not seem to be mentioned anywhere.

Suffice to say, at the time we were not aware of all these details, so for the sake of correctness it was safer to follow the code rather than the papers. This approach came with its own challenges as we had to become acquainted with Fortran as a programming language while deciphering the hopefully unconventional shenanigans that comes with all the quirks Fortran has.
Here is an overview of challenges, inconsistencies, and confusing language quirks we have encountered while working with the xTB project.

\begin{itemize}
        \item The project is written in object-oriented Fortran, which makes the execution flow difficult to follow.
        \item Arrays in Fortran start at 1 by default, but it is possible to specify that it should start at any other index. We have encountered a wide mix of start indices including 0, 1, 5, and 11.
        \item Variable names in Fortran are case-insensitive, and we encountered a variable that was defined with uppercase but referenced with lowercase.
        \item Fortran uses column-major indexing, so we have swapped the indices in Python.
        \item The goto statement exists in Fortran, and has been used inconsistently for something that should have been a simple for loop.
        \item Interfaces in Fortran are a way to overload a method, and it can be difficult to know which function it calls without digging into the subtle type differences of the arguments.
        \item In Fortran 'pure elemental' functions are pure functions that can be given an array in place of any single value argument of the same type. The function will essentially unpack the array and call the function with each element.
        \item Fortran uses parenthesis to index into an array. A subroutine is called by using the 'call' keyword, but pure functions does not. This makes it unclear whether we are calling a pure function or indexing into an array.
\end{itemize}

In addition to these confusing language specifics, there are also numerous structural oddities within the code. They love symmetric cantor pairing functions which are functions that map some multi-dimensional index into a flat 1-dimensional index. They use them to save memory on symmetric matrices where they only need one of the triangles. This works by having a cantor function where indices $(x,y)$ and $(y,x)$ maps to the same index. They use the variable name '\verb|lin|' for the cantor function, which says nothing about what it is. It would be much simpler to understand had they just used a 2-dimensional array.
The non-descriptive variable name leads us to the next point, being that they are allergic to long variable names and therefore desperately tries to keep all names within three letters. This makes it impossible to know what the values actually are and makes the codebase almost unapproachable for new contributors.
Another weird thing we have seen is the use of flag arrays to skip values that are never used in multi-dimensional arrays instead of just having the values we need in a a 1-dimensional array.

Among all of this, even some of the command-line arguments for the program are poorly described. We noticed that it caches previous computations for a molecule, so running it twice on say a C200 molecule, will make the second run much faster. This is undesirable when we need to know what the total computational time is, and so to disable this behavior, the program has the flag seen in \autoref{fig:norestart}.
\begin{figure}[H]
\begin{minted}{text}
    --[no]restart
        restarts calculation from xtbrestart (default = true)
\end{minted}
\caption{The xTB command-line flag that controls whether to continue the computation from the last run.}
\label{fig:norestart}
\end{figure}

The description is ambiguous as it can both mean that we recompute the data stored in \verb|xtbrestart|, or that we reuse the value and continue the computation from there. At first we thought that we would specify \verb|--restart| because we want to restart the whole computation without any caching. In reality what we need is \verb|--norestart| because it should not use \verb|xtbrestart| which is the cache from the previous run.

When porting code from an implementation and a language with so many quirks and pitfalls, it becomes exceedingly important to have tests in place to catch these errors. Having a test suite that enables us to compare our implementation to the original has been indispensible to us for a fast iteration loop that gives insight into the mismatches and any potential patterns in the discrepancies.


\section{Testing}

The xTB Fortran codebase has a large footprint, and there is a lot of overlap between the xTB methods, so even focusing on just one of them still requires a great amount of code.
The large amount of computations we have to deal with when porting the code makes proper validation especially important, as it becomes increasingly easy to make mistakes.With the discrepancies between the paper and the code, in addition to details that seem to go unexplained, we realized that the obvious approach forward was to lean towards the existing implementation rather than the paper.

One of the hurdles from testing against an existing program becomes the lack of transparency regarding the logic that takes place between the initial input and the final output presented to the user. Thankfully, the source code is publicly available, which allows for easy manipulation of the original flow of execution, thus avoiding the hassle of testing against a black box or the need to resort to methods of reverse engineering.

On behalf of these considerations we decided to write patches that allow to intercept the arguments and results of arbitrary functions just by running the program as normal. This gave us the ability to implement and test abritrary functions in an isolated manner, by eliminating the need to compute their arguments.

\subsection{Towards Reproducability with Nix}

An important part of any software is reproducability, and applying certain patches in certain scenarios is something that should preferably be automated, reproducable, and optimally also portable. This is especially important for this approach to validation as it requires a way to reproduce a specific version of xTB linked to the same versions of dependencies. Essentially an exact copy of the original shell environment to ensure that patches work, results are the same, and no new bugs appear in the program itself or its dependencies. All of this should be achievable without having to add, remove, downgrade or upgrade system packages on your system.

The well-known contenders for this is any of the numerous containerization solutions on Linux, such as Docker, Podman, LXC etc. There are some problems with these options though, one being that it can be difficult to truly reproduce package versions without saving the resulting container image, another being that it does not solve the problem of having multiple versions of the same package installed. Some other notable limitations are that it limits the process to run within the container and passing in a GPU or other hardware can be nefariously difficult. A container also does not have access to the X or Wayland session needed to run GUI applications, though that is not currently relevant in this case.

Another approach which has been growing in popularity in recent years are tools that take unique approaches to package management in order to make not only packages reproducable, but also shell environments, system configurations and other forms of "outputs". Two such popular package managers are Nix from the Nix team and Guix from the GNU foundation. Nix is arguably the more popular option and it is also the solution that has been chosen for this project.

Nix is an umbrella term that can refer to either the Nix functional programming language, the package manager, or the Nix based Linux distribution NixOS. The language and package manager go hand in hand and can be used on any Linux distribution. As such, NixOS is not required for the needs of this project and will not be mentioned going forward.

Nix does not follow the Unix Filesystem Hierarchy Standard (FHS), which brings with it some challenges, but this fundamental difference from other package managers is a major part of what makes Nix so powerful.
Rather than installing packages into the usual system paths like `/bin`, `/lib` etc. Nix installs everything into a read-only path called the Nix store under `/nix/store`.
Everything in the Nix store is a result of a core concept in Nix called a derivation, which is essentially a build task to produce some output of files into the Nix store.
All outputs into the store is marked with a custom hash in the filename called a NAR hash. These fundamental ideas fix some common problems such as circular dependencies and allow having multiple versions of the same package installed as they will simply coincide in the Nix store with different NAR hashes.

The typical binary on Linux is dynamically linked against the FHS compliant paths and it is not uncommon to have them hardcoded either. To make use of the packages in the Nix store, it is required to either recompile the program against the store paths, or in the case of proprietary software, patching the ELF header is needed to change the path to the interpreter and to dynamically linked libraries. Thankfully the Nix package repository 'NixPkgs' is the largest and freshest out there\footnote{\url{https://repology.org/repositories/graphs}}, so as a typical user doing this is rarely needed.
Nixpkgs is a version-controlled repository on GitHub, so using older versions of packages even alongside newer ones, is fairly trivial as it simply requires fetching multiple revision of the repository.

This along with the previously mentioned features have allowed a greatly simplified process of not only running the newest version 6.7.1 of the xTB program, but also running the much older nvfortran compatible version 6.4.0 alongside it.
NixPkgs is also a collection of library functions, and the helper functions for making derivations called `mkDerivation` make it easy to define all the stages of packaging a program including unpacking, patching, building, checking, and installing the files.
With this, the whole pipeline of patching, compiling, running, and passing the data over to the Python validation tests can be achieved with a single shell command.

\begin{minted}[linenos=false]{bash}
> nix run .#cmp-impls
\end{minted}


This command takes the form '\verb|nix run <path to flake>#<output>|'. Path to flake refers to a file-tree whose root directory contains a file called 'flake.nix'. Nix flakes is an experimental but widely adopted feature, which provides a standard way to write Nix expressions and a way to manager their dependencies through a version-pinned lock file. The 'flake.nix' file follows a uniform naming schema for declaring inputs and outputs, where inputs are the dependencies, and outputs are Nix expressions to be exposed.
The new Nix command-line interface needed to interact with flakes is naturally also an experimental feature that has to be enabled explicitly. The run command instructs Nix to build and run the derivation 'cmp-impls', which is defined as an app in the flake outputs.

\newpage

\begin{figure}[H]
\begin{minted}{nix}
  {
    inputs = {
      nixpkgs.url = "github:nixos/nixpkgs/nixos-unstable";
    };

    outputs = { self, nixpkgs, ... }: {
      apps."x86_64-linux" = let
        pkgs = nixpkgs.legacyPackages."x86_64-linux";
        ...
      in {
        "cmp-impls" = let
          python = (pkgs.python3.withPackages (python-pkgs: with python-pkgs; [
            numpy scipy cvxopt
          ]));
        in {
          type = "app";
          program = toString (pkgs.writeShellScript "cmp-impls" ''
            PYTHONPATH=${pkgs.lib.cleanSource ./xtb-python} exec ${python}/bin/python \
              ${./xtb-python/cmp_impls.py} ${xtb_test_data}
          '');
        };
      };
      ...
    };
  }
\end{minted}
\caption{This is a snippet of our Nix flake which shows the app declaration for running our test suite. The app depends on the derivation that generates the test data.}
\label{fig:nix-flake}
\end{figure}

Python is declared with the required packages and is then used in the app to call the \verb|cmp_impls.py| script. The script is called with the test data acquired from running the Fortran xTB program. This data comes from another derivation which executes patched versions of xTB and DFT-D4 on a C200 fullerene to get the relevant function arguments and results as binary files.

\begin{figure}[H]
\begin{minted}{nix}
  xtb_test_data = builtins.derivation {
    name = "xtb-test-data";
    system = "x86_64-linux";
    builder = "${pkgs.bash}/bin/bash";
    src = ./xtb-python/data/C200.xyz;
    args = ["-c" ''
      PATH=$PATH:${pkgs.coreutils}/bin
      mkdir -p ./calls/{build_SDQH0,coordination_number,\
        dim_basis,dtrf2,electro,form_product,get_multiints,\
        h0scal,horizontal_shift,multipole_3d,newBasisset, olapp}
      ${xtb}/bin/xtb $src
      ${dftd4}/bin/dftd4 $src
      mv calls $out
    ''];
  };
\end{minted}
\caption{This is the Nix derivation for generating the test data from our patched versions of xTB and dftd4.}
\label{fig:xtb-test-data}
\end{figure}

The directories for the binary files are created in advance as checking whether they exist when writing the binary files has a large overhead.
This derivation in turn uses derivations for xTB and DFT-D4. Luckily DFT-D4 is already in NixPkgs, but it still needs to be patched in order to extract the required data for validation. Thankfully the \verb|mkDerivation| function used in NixPkgs makes overriding and patching a package very straightforward. 

\begin{figure}[H]
\begin{minted}{nix}
  dftd4 = (pkgs.dftd4.overrideAttrs (finalAttrs: previousAttrs: {
    src = pkgs.fetchFromGitHub {
      owner = "dftd4";
      repo = "dftd4";
      rev = "502d7c59bf88beec7c90a71c4ecf80029794bd5e";
      hash = "sha256-FEABtBAZK0xQ1P/Pbj5gUuvKf8/ZLITXaXYB+btAY/8=";
    };
    buildInputs = [ multicharge ] ++ previousAttrs.buildInputs;
    doCheck = false;
    patches = previousAttrs.patches ++ [
      ./nix/patches/dftd4/use_gfn2.patch
      ./nix/patches/dftd4/log_args_and_outputs.patch
    ];
  }));
\end{minted}
\caption{This is the Nix expression for overriding the dftd4 package derivation. We essentially update dftd4 to a newer revision and add patches to logs arguments and results to a binary file, and another patch to use GFN2.}
\label{fig:dftf4-drv}
\end{figure}

The version is bumped by overriding the source, and the multicharge project is added from NixPkgs and also bumped as a requirement of this newer version. Some of the tests were timing out, so they have been disabled by setting \verb|doCheck| to false. Lastly the patches are applied by providing the relevant patch files.

xTB and two of its dependencies, namely CPCM-X and numsa are not in NixPkgs and had to be packaged from scratch.

\subsection{Patching xTB}

Now we have a way to apply patches and repoduce our tests. Next we will dive into what the patches do and how they are used.
All the patches follow the structure seen in \autoref{fig:patchfile} where the original function is prefixed with a 'g', such that the new wrapper function will be called instead. The wrapper function writes the function arguments to a binary file before calling the actual function before finally writing the result of the function to the same binary file.
Writing a file for each call to a function is a bit excessive and will produce a very large amount of files, so a threshold has been used to create an upperbound on the number of files that can be created for each function.

\begin{figure}[H]
\begin{minted}[linenos=false]{diff}
+   logical :: hit_threshold
+   integer :: u
+   character(len=200) :: path
+
+   hit_threshold = testfile_path('electro', path)
+   if (.not.hit_threshold) then
+     open(newunit=u, file=trim(path), form='unformatted', access='stream')
+     write(u) nbf
+     write(u) size(H0), H0
+     write(u) size(P, 1), size(P, 2), P
...
+     if (allocated(ies%thirdOrder%atomicGam)) then
+       write(u) size(ies%thirdorder%atomicgam), ies%thirdorder%atomicgam
+     else
+       write(u) 0
+     end if
...
+     write(u) size(ies%jmat, 1), size(ies%jmat, 2), ies%jmat
+     write(u) size(ies%shift), ies%shift
+   end if
+
+   call gelectro(n,at,nbf,nshell,ies,H0,P,dq,dqsh,es,scc)
+
+   if (.not.hit_threshold) then
+     write(u) es
+     write(u) scc
+     close(u)
+   end if
\end{minted}
\caption{This is a diff file for the electro energy function. A diff file reflects the changes between two files and can be used to patch code by applying these changes. All our patches follow this structure of writing the arguments to a file, then running the original function before finally writing the result to the same binary file.}
\label{fig:patchfile}
\end{figure}

\subsection{Implementing the Tests}

With the binary files containing the arguments and results, we now have all the data necessary to compare against our Python implementation. We have made a test suite in the file \verb|cmp-impls.py| where all tests follow these same steps:

\begin{enumerate}
   \item Load an deserialize a binary file for the appropriate function
   \item Call the corresponding Python function with the deserialized arguments
   \item Compare the result against the deserialized Fortran result
   \item Repeat until there are no more binary files for this function
\end{enumerate}


\begin{figure}[H]
\begin{minted}{python}
  def test_electro():
      fn_name = "electro"
      for i, file_path in enumerate(glob.glob(f'{directory}/{fn_name}/*.bin')):
          with open(file_path, 'rb') as f:
              def read_ints(n=1):
                  return np.fromfile(f, dtype=np.int32, count=n)

              nbf = read_ints(1)[0]
              H01 = read_ints(1)[0]
              H0 = np.fromfile(f, dtype=np.float64, count=H01)
              m, n = read_ints(2)
              P = np.fromfile(f, dtype=np.float64, count=m * n).reshape((n, m))
              ...
              atomicGam1 = read_ints(1)[0]
              atomicGam = None  if atomicGam1 == 0
                                else np.fromfile(f, dtype=np.float64, count=atomicGam1)
              ...
              es_res, scc_res = read_reals(2)
              es, scc = electro(nbf, H0, P, dq, dqsh, atomicGam, shellGam, jmat, shift)

              is_equal(es, es_res, "es", fn_name)
              is_equal(scc, scc_res, "scc", fn_name)

      print(f"matches! [{fn_name}]")
\end{minted}
\caption{This is some of the code from the test for the electro function. It shows how we iterate through each binary file, deserialize its data, call the corresponding Python implementation, and then compare the results.}
\label{fig:testcode}
\end{figure}
